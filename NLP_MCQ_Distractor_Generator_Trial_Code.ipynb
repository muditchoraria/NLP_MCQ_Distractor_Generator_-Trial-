{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_MCQ_Distractor_Generator_Trial_Code.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbbN8zSdEm4A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "02d70002-d177-455b-b14b-992bd7b086d5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzSZQhjME68y",
        "colab_type": "text"
      },
      "source": [
        "**IMPORT THE REQUIRED LIBRARIES**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLyOKnTDEzm9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pandas import DataFrame,Series\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_lZBk62GJgA",
        "colab_type": "text"
      },
      "source": [
        "**IMPORT DATASETS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVlR6tE1EziL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/MCQ Distractor Generator NLP/Test.csv\")\n",
        "train = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/MCQ Distractor Generator NLP/Train.csv\", sep = ',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlK0FjgTP3H9",
        "colab_type": "text"
      },
      "source": [
        "Data preprocessing\n",
        "\n",
        "1. Split the distractor sentence into parts by using comma separator. excel\n",
        "2.  colmns will be present - question , answer_text, dis1, dis2, dis3\n",
        "3.Create corpus\n",
        "Iterate over the rows for inderstanding context\n",
        "perform \n",
        "bagging\n",
        "stem\n",
        "lemma\n",
        "sequence of words\n",
        "entity of words\n",
        "\n",
        "3. Train the models\n",
        "3. Understand the general NLP process and NLG techniques\n",
        "4. Generate 3 distractors for each question, so train for each TRAIN distractor and generate TEST distrator.\n",
        "\n",
        "Train\n",
        " - X = q,a\n",
        " - Y = d1 or d2 or d3\n",
        " \n",
        "Test \n",
        " - X = q,a\n",
        " - Y = d1 or d2 or d3\n",
        " \n",
        " \n",
        "5. Join those 3 TEST distractors by comma's and check for submission."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AN55-A8B_hHa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "0f805814-3a14-4f0e-8cc5-50a0955e7f33"
      },
      "source": [
        "print(train.isnull().sum(),'\\n')\n",
        "print(test.isnull().sum())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "question       0\n",
            "answer_text    0\n",
            "distractor     0\n",
            "dtype: int64 \n",
            "\n",
            "question       0\n",
            "answer_text    0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waBv_gwLEzfm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# new data frame with split value columns\n",
        "\n",
        "trainy = train['distractor'].str.split(\",\", n = 2, expand = True)\n",
        "\n",
        "#----------------------------------------------------------------\n",
        "\n",
        "# making 3 separate columns from new dataframe \n",
        "\n",
        "train['distractor'] = trainy[0]\n",
        "\n",
        "train['distractor'] = trainy[1]\n",
        "\n",
        "train['distractor'] = trainy[2]\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "\n",
        "# dropping old column names\n",
        "train.drop(columns = [\"distractor\"], inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hV2_ZpTA702",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d155ab96-0563-4fac-c368-26f2acef4d53"
      },
      "source": [
        "trainy.head()\n",
        "trainy.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31499, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M20AuNC_EzbZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ab14a67b-5a0b-4216-9f9d-6fe096a32db7"
      },
      "source": [
        "train.head()\n",
        "train.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31499, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUMhCGE7Cx1f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# concat 2 dataframes on axis 1\n",
        "new_train = pd.concat([train, trainy], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82NZ9heTDD2Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "722eeb52-878a-4431-ef21-c63b567ff201"
      },
      "source": [
        "# renaming columns\n",
        "\n",
        "new_train.columns = ['question','answer','distractor_1','distractor_2','distractor_3']\n",
        "new_train.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>distractor_1</th>\n",
              "      <th>distractor_2</th>\n",
              "      <th>distractor_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Meals can be served</td>\n",
              "      <td>in rooms at 9:00 p. m.</td>\n",
              "      <td>'outside the room at 3:00 p. m.'</td>\n",
              "      <td>'in the dining - room at 6:00 p. m.'</td>\n",
              "      <td>'in the dining - room from 7:30 a. m. to 9:15...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>It can be inferred from the passage that</td>\n",
              "      <td>The local government can deal with the problem...</td>\n",
              "      <td>'If some tragedies occur again '</td>\n",
              "      <td>' relevant departments of the State Council s...</td>\n",
              "      <td>'Currently ', ' the central government has es...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The author called Tommy 's parents in order to</td>\n",
              "      <td>help them realize their influence on Tommy</td>\n",
              "      <td>'blame Tommy for his failing grades'</td>\n",
              "      <td>'blame Tommy for his failing grades'</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>It can be inferred from the passage that</td>\n",
              "      <td>the writer is not very willing to use idioms</td>\n",
              "      <td>'idioms are the most important part in a langu...</td>\n",
              "      <td>'nonnative speakers should learn more idioms'</td>\n",
              "      <td>'there are no ways to master idioms'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How can we deal with snake wounds according to...</td>\n",
              "      <td>Stay calm and do n't move .</td>\n",
              "      <td>'Cut the wound and suck the poison out .'</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question  ...                                       distractor_3\n",
              "0                                Meals can be served  ...   'in the dining - room from 7:30 a. m. to 9:15...\n",
              "1           It can be inferred from the passage that  ...   'Currently ', ' the central government has es...\n",
              "2     The author called Tommy 's parents in order to  ...                                               None\n",
              "3           It can be inferred from the passage that  ...               'there are no ways to master idioms'\n",
              "4  How can we deal with snake wounds according to...  ...                                               None\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1PLI4haEzW6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "e34e1162-ce0b-4a5f-bcad-f4b0c20e0794"
      },
      "source": [
        "train.info()\n",
        "train.describe()\n",
        "train.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 31499 entries, 0 to 31498\n",
            "Data columns (total 2 columns):\n",
            "question       31499 non-null object\n",
            "answer_text    31499 non-null object\n",
            "dtypes: object(2)\n",
            "memory usage: 492.2+ KB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31499, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezWGF_xTEzSF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "e2316c33-d04f-4fbb-ab13-3d72cb22cf8f"
      },
      "source": [
        "test.info()\n",
        "test.describe()\n",
        "test.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 13500 entries, 0 to 13499\n",
            "Data columns (total 2 columns):\n",
            "question       13500 non-null object\n",
            "answer_text    13500 non-null object\n",
            "dtypes: object(2)\n",
            "memory usage: 211.0+ KB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13500, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XbbJRpuEvWY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "aa47d336-3274-4476-803a-dd8f68f963f6"
      },
      "source": [
        "new_train.info()\n",
        "new_train.describe()\n",
        "new_train.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 31499 entries, 0 to 31498\n",
            "Data columns (total 5 columns):\n",
            "question        31499 non-null object\n",
            "answer          31499 non-null object\n",
            "distractor_1    31499 non-null object\n",
            "distractor_2    22348 non-null object\n",
            "distractor_3    13595 non-null object\n",
            "dtypes: object(5)\n",
            "memory usage: 1.2+ MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31499, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNJKSScwEzO6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "18a64358-dc57-40d9-c9ac-95cb61abb599"
      },
      "source": [
        "31499 + 13500"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAekvgzUsakY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "bdc59ad9-3018-41a4-c78b-7e98c9d48a0f"
      },
      "source": [
        "new_train.isnull().sum()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "question            0\n",
              "answer              0\n",
              "distractor_1        0\n",
              "distractor_2     9151\n",
              "distractor_3    17904\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1K4caGSIcrr",
        "colab_type": "text"
      },
      "source": [
        "**TREAT NULL VALUES**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6cOPkgGImiE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dropping column with any null values \n",
        "# new_train = new_train.dropna(axis = 1, how ='any', inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3O0HwpKImUd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "854d0ac0-928f-4bf6-8d49-e7b2a17cfac7"
      },
      "source": [
        "new_train.isnull().sum()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "question            0\n",
              "answer              0\n",
              "distractor_1        0\n",
              "distractor_2     9151\n",
              "distractor_3    17904\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9j3eA-wZGbjY",
        "colab_type": "text"
      },
      "source": [
        "**REMOVE PUNCTUTATION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWgST456F57Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "53385aa4-868e-401c-87de-950ffb399714"
      },
      "source": [
        "import string\n",
        "string.punctuation"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWZ22zS5xJVL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to remove punctuation\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    text_no_punctuation = \"\".join([char for char in text if char not in string.punctuation])\n",
        "    return text_no_punctuation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLivj7v0xJSe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# new_train['dist1_clean'] = new_train['distractor_1'].apply(lambda x:remove_punctuation(x))\n",
        "# new_train['dist2_clean'] = new_train['distractor_2'].apply(lambda x:remove_punctuation(x))\n",
        "# new_train['dist3_clean'] = new_train['distractor_3'].apply(lambda x:remove_punctuation(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTVR3JXohqYe",
        "colab_type": "text"
      },
      "source": [
        "**TOKENIZATION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdlUrV7Ps2Mf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "# function to convert to lower case and tokenize.\n",
        "def tokenize(text):\n",
        "    tokens = re.split('\\W+', text )\n",
        "    return tokens "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kB8Nd3crthF6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# new_train['dist1_clean_token'] = new_train['dist1_clean'].apply(lambda x: tokenize(x.lower()))\n",
        "# new_train['dist2_clean_token'] = new_train['dist2_clean'].apply(lambda x: tokenize(x.lower()))\n",
        "# new_train['dist3_clean_token'] = new_train['dist3_clean'].apply(lambda x: tokenize(x.lower()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "450sfQNHjFxN",
        "colab_type": "text"
      },
      "source": [
        "**REMOVE STOPWORDS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwcGr_HJt64B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "70a3ccae-59dd-4bb8-f9db-7d0bb9fb9682"
      },
      "source": [
        "import gensim\n",
        "from gensim import corpora\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7UgCmchjWpu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stopword = nltk.corpus.stopwords.words('english')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fU4oDPD0kI4U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to remove stopwords\n",
        "def remove_stopwords(tokenized_list):\n",
        "    text = [word for word in tokenized_list if word not in stopword] \n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VX3rDRSrlD6X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# new_train['dist1_clean_token_no_sw'] = new_train['dist1_clean_token'].apply(lambda x: remove_stopwords(x))\n",
        "# new_train['dist2_clean_token_no_sw'] = new_train['dist2_clean_token'].apply(lambda x: remove_stopwords(x))\n",
        "# new_train['dist3_clean_token_no_sw'] = new_train['dist3_clean_token'].apply(lambda x: remove_stopwords(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "890BNQM7m85s",
        "colab_type": "text"
      },
      "source": [
        "**STEMMING OR LEMMATIZING** \n",
        "\n",
        "1. PERFORM ONLY ONE OF THE ABOVE\n",
        "2. STEM - ROOT WORD WITHOUT TAKING CONTEXT INTO CONSIDERATION\n",
        "3. LEMMA - ROOT WORD WHILE TAKING CONTEXT INTO CONSIDERATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCjv3cGvoahT",
        "colab_type": "text"
      },
      "source": [
        "**STEMMING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Faevbgklm8co",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "perf_stem = nltk.PorterStemmer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBYMSkR-m8Zw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to perform stemming\n",
        "def stemming(toeknized_text):\n",
        "    text = [perf_stem.stem(word) for word in tokenized_text]\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhBe73GYoApb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# new_train['dist1_clean_token_no_sw_stem'] = new_train['dist1_clean_token_no_sw'].apply(lambda x: stemming(x))\n",
        "# new_train['dist2_clean_token_no_sw_stem'] = new_train['dist2_clean_token_no_sw'].apply(lambda x: stemming(x))\n",
        "# new_train['dist3_clean_token_no_sw_stem'] = new_train['dist3_clean_token_no_sw'].apply(lambda x: stemming(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lq5afzzZojig",
        "colab_type": "text"
      },
      "source": [
        "**LEMMATIZING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lGttKHlpBIL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "per_lemma = nltk.WordNetLemmatizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Nt73jKNoXrk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to perform lemmatization.\n",
        "def lemmatizing(tokenized_tex):\n",
        "    text = [perf_lemma(word) for word in tokenized_text]\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GO658Petpeef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# new_train['dist1_clean_token_no_sw_lemma'] = new_train['dist1_clean_token_no_sw'].apply(lambda x: lemmatizing(x))\n",
        "# new_train['dist2_clean_token_no_sw_lemma'] = new_train['dist2_clean_token_no_sw'].apply(lambda x: lemmatizing(x))\n",
        "# new_train['dist3_clean_token_no_sw_lemma'] = new_train['dist3_clean_token_no_sw'].apply(lambda x: lemmatizing(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKwlNeCtpvu1",
        "colab_type": "text"
      },
      "source": [
        "**SPLITTING THE DATASET**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0h-zJropfqM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = new_train[['question','answer']]\n",
        "# y1 = new_train['dist1_clean_token_no_sw']\n",
        "# y2 = new_train['dist2_clean_token_no_sw']\n",
        "# y3 = new_train['dist3_clean_token_no_sw']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUxRzBo9A6fB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsaNzW9-Btsd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GR7Co3e9GElC",
        "colab_type": "text"
      },
      "source": [
        "**MODEL BUILDING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6p1mo3pGG-S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0fd69a08-f480-42ad-da59-b1664c22dc13"
      },
      "source": [
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9vYC4ZPGMNo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[0], X.shape[1])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKbKaggWJO31",
        "colab_type": "text"
      },
      "source": [
        "**FIT THE MODEL** ON ALL THE **3 TRAIN DISTRACTORS** FOR GENERATING **3 NEW TEST DISTRACTORS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QHC-rfSG8GD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model.fit(X, y1, epochs=20, batch_size=128, callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GC3_KkBmIGCe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X, y2, epochs=20, batch_size=128, callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gek_beXAII_G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X, y3, epochs=20, batch_size=128, callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQmm3-cXIb62",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # generate characters\n",
        "# for i in range(1000):\n",
        "# \tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "# \tx = x / float(n_vocab)\n",
        "# \tprediction = model.predict(x, verbose=0)\n",
        "# \tindex = numpy.argmax(prediction)\n",
        "# \tresult = int_to_char[index]\n",
        "# \tseq_in = [int_to_char[value] for value in pattern]\n",
        "# \tsys.stdout.write(result)\n",
        "# \tpattern.append(index)\n",
        "# \tpattern = pattern[1:len(pattern)]\n",
        "# print \"\\nDone.\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH5Y-1T_G_Ty",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Load Larger LSTM network and generate text\n",
        "# import sys\n",
        "# import numpy\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import Dense\n",
        "# from keras.layers import Dropout\n",
        "# from keras.layers import LSTM\n",
        "# from keras.callbacks import ModelCheckpoint\n",
        "# from keras.utils import np_utils\n",
        "# # load ascii text and covert to lowercase\n",
        "# filename = \"wonderland.txt\"\n",
        "# raw_text = open(filename, 'r', encoding='utf-8').read()\n",
        "# raw_text = raw_text.lower()\n",
        "# # create mapping of unique chars to integers, and a reverse mapping\n",
        "# chars = sorted(list(set(raw_text)))\n",
        "# char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "# int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
        "# # summarize the loaded data\n",
        "# n_chars = len(raw_text)\n",
        "# n_vocab = len(chars)\n",
        "# print \"Total Characters: \", n_chars\n",
        "# print \"Total Vocab: \", n_vocab\n",
        "# # prepare the dataset of input to output pairs encoded as integers\n",
        "# seq_length = 100\n",
        "# dataX = []\n",
        "# dataY = []\n",
        "# for i in range(0, n_chars - seq_length, 1):\n",
        "# \tseq_in = raw_text[i:i + seq_length]\n",
        "# \tseq_out = raw_text[i + seq_length]\n",
        "# \tdataX.append([char_to_int[char] for char in seq_in])\n",
        "# \tdataY.append(char_to_int[seq_out])\n",
        "# n_patterns = len(dataX)\n",
        "# print \"Total Patterns: \", n_patterns\n",
        "# # reshape X to be [samples, time steps, features]\n",
        "# X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "# # normalize\n",
        "# X = X / float(n_vocab)\n",
        "# # one hot encode the output variable\n",
        "# y = np_utils.to_categorical(dataY)\n",
        "# # define the LSTM model\n",
        "# model = Sequential()\n",
        "# model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "# model.add(Dropout(0.2))\n",
        "# model.add(LSTM(256))\n",
        "# model.add(Dropout(0.2))\n",
        "# model.add(Dense(y.shape[1], activation='softmax'))\n",
        "# # load the network weights\n",
        "# filename = \"weights-improvement-47-1.2219-bigger.hdf5\"\n",
        "# model.load_weights(filename)\n",
        "# model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "# # pick a random seed\n",
        "# start = numpy.random.randint(0, len(dataX)-1)\n",
        "# pattern = dataX[start]\n",
        "# print \"Seed:\"\n",
        "# print \"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\"\n",
        "# # generate characters\n",
        "# for i in range(1000):\n",
        "# \tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "# \tx = x / float(n_vocab)\n",
        "# \tprediction = model.predict(x, verbose=0)\n",
        "# \tindex = numpy.argmax(prediction)\n",
        "# \tresult = int_to_char[index]\n",
        "# \tseq_in = [int_to_char[value] for value in pattern]\n",
        "# \tsys.stdout.write(result)\n",
        "# \tpattern.append(index)\n",
        "# \tpattern = pattern[1:len(pattern)]\n",
        "# print \"\\nDone.\""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}